# ğŸ¯ **Objectifs**

_Documenter lâ€™Ã©volution de chaque brique du projet, garantir une approche structurÃ©e et scientifique, et prÃ©parer une mise en production robuste._

Rien que Ã§a... Pour y parvenir, il va falloir garder en tÃªte une ligne conductrice et s'y tenir... Pas toujours Ã©vident.
En dÃ©butant ma formation, je me suis trÃ¨s rapidement aperÃ§u de la diversitÃ© des choses Ã  connaÃ®tre et donc de la difficultÃ© de ne pas trop s'Ã©parpiller. J'adore cette . Si j'ai bien une quÃªte professionnelle, c'est de trouver le boulot qui m'enrichisse quotidiennement. Et je crois avoir choisi la bonne voie...

Revenons Ã  notre projet.. Les questions qui m'animent sont nombreuses. Je me demande par oÃ¹ commencer. Dois-je visualiser l'UI/UX pour avoir un rendu concret et adapter le code par la suite ? Dois-je m'attaquer directement au machine learning en testant des modÃ¨les? Dois-je anticipier l'architecture de dÃ©ploiement avant d'avoir un premier modÃ¨le fonctionnel? Difficile de trouver une rÃ©ponse claire. Je vais donc prendre en considÃ©ration ma formation de data product manager pour orienter mes choix. Que souhaiterait un client? Quel impact attend-on d'un point de vue business? Quelles seront les contraintes d'infractrusture? Comment les utilisateurs intÃ©ragiront avec nos recommandations? En obtenant une meilleure vision des parties prenantes, il sera plus facile d'aborder une dÃ©marche pragmatique.

### **1. Affiner les briques existantes**

- **ğŸ“¦ DonnÃ©es**

  - *Objectif*â€¯: Exploiter scientifiquement le dataset MovieLens (20M+ de notes) pour en extraire des insights exploitables.
  - *Actions*â€¯:
    - Valider lâ€™intÃ©gritÃ© des donnÃ©es (sommes de contrÃ´le, analyse des missing values).
    - Explorer le _Tag Genome_ pour enrichir les features des films.
    - Documenter chaque Ã©tape de preprocessing dans des notebooks dÃ©diÃ©s.

- **ğŸ¬ SystÃ¨mes de recommandation**

  - *Objectif*â€¯: ImplÃ©menter, comparer et optimiser 3 approches (collaborative, contenu, hybride).
  - *Actions*â€¯:
    - Benchmark des algorithmes (k-NN, factorisation de matrices, deep learning).
    - Mesurer lâ€™impact des mÃ©triques de similaritÃ© (cosinus, Pearson) sur les rÃ©sultats.
    - Tester des combinaisons hybrides (exâ€¯: filtrage collaboratif + NLP sur les tags).

- **âš™ï¸ MLOps**
  - *Objectif*â€¯: Industrialiser chaque phase du projet pour un dÃ©ploiement fiable.
  - *Actions*â€¯:
    - **Dockeriser** lâ€™environnement (isolation des dÃ©pendances).
    - **Orchestrer** les workflows avec **Airflow** (entraÃ®nements rÃ©currents, prÃ©traitements).
    - **Surveiller** les modÃ¨les en production via **Prometheus/Grafana** (dÃ©rive des donnÃ©es, performance en temps rÃ©el).

---

### **2. Indicateurs de progression**

Pour chaque brique, le cahier de bord incluraâ€¯:

- âœ… **Checklists** des Ã©tapes validÃ©es (exâ€¯: _DonnÃ©es nettoyÃ©es_, _ModÃ¨le collaboratif entraÃ®nÃ©_).
- ğŸ“Š **Metrics comparatives** entre les approches (prÃ©cision, recall, temps dâ€™exÃ©cution).
- ğŸ **Journal des problÃ¨mes rencontrÃ©s** et correctifs appliquÃ©s (exâ€¯: _fuite de donnÃ©es dÃ©tectÃ©e le 15/06_).
- ğŸ“‚ **Liens versionnÃ©s** vers le code (GitHub), les modÃ¨les (MLflow) et les artefacts (Docker Hub).

---

### **3. Feuille de route**

- **Phase 1** (2 semaines)â€¯: Exploration des donnÃ©es + MVP du filtrage collaboratif.
- **Phase 2** (3 semaines)â€¯: ImplÃ©mentation des approches hybrides + tests A/B.
- **Phase 3** (1 semaine)â€¯: IntÃ©gration CI/CD (tests automatisÃ©s avec GitHub Actions).
- **Phase 4** (1 semaine)â€¯: DÃ©ploiement et monitoring avec alertes Slack/Prometheus.

---

### **4. Philosophie du projet**

- **ItÃ©ratif**â€¯: Chaque brique est conÃ§ue pour Ã©voluer indÃ©pendamment (_exâ€¯: remplacer un modÃ¨le sans toucher au preprocessing_).
- **Transparent**â€¯: Toutes les dÃ©cisions techniques sont justifiÃ©es par des donnÃ©es (logs, mÃ©triques, visualisations).
- **Reproductible**â€¯: Un collaborateur doit pouvoir relancer lâ€™intÃ©gralitÃ© du pipeline avec `docker-compose up` et une commande.
