# üéØ **Objectifs**

_Documenter l‚Äô√©volution de chaque brique du projet, garantir une approche structur√©e et scientifique, et pr√©parer une mise en production robuste._

Pour y parvenir, il va falloir garder en t√™te une ligne conductrice et s'y tenir... Pas toujours √©vident au regard de ma curiosit√©.

Revenons √† notre projet.. Les questions qui m'animent sont nombreuses. Je me demande par o√π commencer. Dois-je visualiser l'UI/UX pour avoir un rendu concret et adapter le code par la suite ? Dois-je m'attaquer directement au machine learning en testant des mod√®les? Dois-je anticipier l'architecture de d√©ploiement avant d'avoir un premier mod√®le fonctionnel? Difficile de trouver une r√©ponse claire. Je vais donc prendre en consid√©ration ma formation de data product manager pour orienter mes choix. Que souhaiterait un client? Quel impact attend-on d'un point de vue business? Quelles seront les contraintes d'infractrusture? Comment les utilisateurs int√©ragiront avec nos recommandations? En obtenant une meilleure vision des parties prenantes, il sera plus facile d'aborder une d√©marche pragmatique.

Des clients, j'en ai pas. Il va donc falloir √™tre imaginatif et se challenger tout seul. Je veux arriver √† cr√©er une application web avec une base de donn√©es utilisateurs. Si un utilisateur n'est pas identifi√©, on lui demande de cr√©er un compte. Il va ensuite devoir choisir 5 films qu'il aime, soit par une recherche sur le titre, soit en choississant en fonction des propositions que nous lui ferons. Ceci nous permettra ensuite de lui proposer 5 films qui pourraient lui convenir. Ok pour l'id√©e principale.

Voici maintenant les bases qui me serviront de fil d'Ariane:

---

## Reproductibilit√© et versionnement (GitHub, MLflow)

Pour garantir la reproductibilit√© du projet, nous versionnons syst√©matiquement tout le code. √Ä chaque modification, que ce soit sur les scripts de pr√©traitement des donn√©es, les notebooks ou les fichiers de configuration (requirements.txt, Dockerfile, etc.), nous utilisons Git. Cela nous permet de garder une trace pr√©cise de l‚Äô√©volution du projet et de revenir facilement √† une version ant√©rieure si besoin.

Nous versionnons √©galement les mod√®les. Gr√¢ce √† MLflow, nous enregistrons chaque version de mod√®le entra√Æn√©, en y associant les hyperparam√®tres, les m√©triques de performance et les artefacts produits. Cette d√©marche nous assure de pouvoir reproduire n‚Äôimporte quelle exp√©rimentation et de comparer objectivement les r√©sultats obtenus.

Pour aller plus loin, nous documentons les versions des jeux de donn√©es utilis√©s pour l‚Äôentra√Ænement et les tests. Nous gardons aussi une trace des environnements d‚Äôex√©cution, par exemple via des fichiers YAML ou Docker, afin de garantir que chaque exp√©rience puisse √™tre relanc√©e dans des conditions identiques.

Enfin, nous accordons une grande importance √† la documentation. Nous d√©crivons chaque exp√©rience, les choix d‚Äôarchitecture, les r√©sultats et les it√©rations dans une documentation vivante, r√©alis√©e avec MkDocs. Cela permet √† toute personne rejoignant le projet de comprendre rapidement les d√©cisions prises et les √©tapes franchies.

---

## Automatisation et CI/CD (GitHub Actions)

Nous automatisons les tests en mettant en place des tests unitaires et d‚Äôint√©gration pour l‚Äôensemble du code, qu‚Äôil s‚Äôagisse de l‚ÄôAPI ou des scripts de recommandation. Ces tests sont d√©clench√©s automatiquement √† chaque push ou pull request gr√¢ce √† GitHub Actions. Cela nous assure de d√©tecter rapidement toute r√©gression ou bug introduit lors du d√©veloppement.

Nous avons √©galement int√©gr√© une √©tape de validation automatique des mod√®les. Avant toute mise en production d‚Äôun nouveau mod√®le, nous contr√¥lons syst√©matiquement ses performances sur un jeu de test. Ce processus garantit que seuls les mod√®les r√©pondant √† nos crit√®res de qualit√© sont d√©ploy√©s.

Le d√©ploiement de l‚Äôapplication web, de l‚ÄôAPI de recommandation et des mod√®les est lui aussi automatis√© via GitHub Actions. Nous pouvons ainsi d√©ployer rapidement sur un serveur ou un cluster cloud, tout en gardant un historique pr√©cis des versions mises en production.

Enfin, nous avons pr√©vu la possibilit√© de revenir facilement √† une version ant√©rieure du mod√®le ou de l‚Äôapplication en cas de probl√®me, afin d‚Äôassurer la continuit√© du service.

---

## Orchestration des workflows (Apache Airflow)

Nous d√©coupons nos pipelines en t√¢ches ind√©pendantes : ingestion des donn√©es, pr√©traitement, entra√Ænement, √©valuation, d√©ploiement. Cette structuration nous permet de mieux organiser le travail et d‚Äôoptimiser les ressources.

Avec Airflow, nous d√©finissons pr√©cis√©ment l‚Äôordre d‚Äôex√©cution des t√¢ches et leurs d√©pendances. Cela nous permet de relancer uniquement les √©tapes √©chou√©es, sans avoir √† tout reprendre depuis le d√©but.

Nous planifions √©galement des t√¢ches r√©currentes, comme le r√©entra√Ænement du mod√®le ou la mise √† jour des recommandations, afin de garantir que notre syst√®me reste performant dans le temps.

L‚Äôinterface d‚ÄôAirflow nous offre un monitoring en temps r√©el de l‚Äô√©tat des t√¢ches. Nous pouvons ainsi d√©tecter rapidement les erreurs et relancer les jobs si n√©cessaire.

---

## Isolation et portabilit√© (Docker)

Pour assurer la portabilit√© et l‚Äôisolation de chaque composant du projet, nous cr√©ons un Dockerfile d√©di√© pour l‚ÄôAPI, l‚Äôapplication web, le pipeline de machine learning et le monitoring. Chaque service fonctionne ainsi dans son propre conteneur, ce qui √©vite les conflits de d√©pendances et facilite la mont√©e en production.

En d√©veloppement local, nous utilisons Docker Compose pour orchestrer l‚Äôensemble des services (API, base de donn√©es, Prometheus, Grafana, etc.). Cela simplifie grandement les tests et la gestion des environnements.

Nous veillons √† ce que toutes les d√©pendances soient soigneusement list√©es dans les fichiers de configuration Docker, afin d‚Äô√©viter toute incompatibilit√© entre les diff√©rents environnements.

---

## D√©ploiement et surveillance (Prometheus & Grafana)

Nous int√©grons dans notre API des endpoints qui exposent des m√©triques (latence, taux d‚Äôerreur, nombre de requ√™tes, etc.) au format Prometheus. Prometheus est configur√© pour scruter r√©guli√®rement ces endpoints et stocker les m√©triques dans sa base de donn√©es time-series.

Nous connectons ensuite Grafana √† Prometheus pour cr√©er des dashboards personnalis√©s. Ceux-ci nous permettent de visualiser la sant√© de l‚ÄôAPI, la performance du mod√®le (pr√©cision, recall, etc.) et la distribution des donn√©es entrantes, notamment pour d√©tecter tout ph√©nom√®ne de drift.

Des r√®gles d‚Äôalerte sont mises en place dans Grafana : par exemple, en cas de latence trop √©lev√©e, de d√©rive du mod√®le ou de baisse de la pr√©cision, nous recevons imm√©diatement une notification par Slack ou email.

Enfin, nous surveillons la d√©rive des donn√©es en int√©grant des m√©triques sp√©cifiques et en configurant des alertes d√©di√©es, afin de pouvoir r√©agir rapidement √† tout changement anormal dans les donn√©es ou les performances du mod√®le[1].
